{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-935064a44540>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#from tensorflow import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 69\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional, Conv1D, MaxPooling1D, Flatten, concatenate, Input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x = np.load('E:/x_r.npy')\n",
    "y = np.load('E:/y_r.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5ef24b76073b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtower_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m760\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "cells = 5\n",
    "filters = 20\n",
    "pool = 2\n",
    "\n",
    "input_shape = Input(shape=(x.shape[1],x.shape[2]))\n",
    "\n",
    "tower_1 = Conv1D(filters=filters, kernel_size=7, activation='relu', input_shape=(760, 1))(input_shape)\n",
    "tower_1 = MaxPooling1D(pool_size=pool)(tower_1)\n",
    "tower_1 = Dropout(0.5)(tower_1)\n",
    "\n",
    "'''tower_2 = MaxPooling1D(pool_size=2)(input_shape)\n",
    "tower_2 = Conv1D(filters=filters, kernel_size=7, activation='relu', input_shape=(760, 1))(tower_2)\n",
    "tower_2 = MaxPooling1D(pool_size=pool)(tower_2)\n",
    "tower_2 = Dropout(0.5)(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling1D(pool_size=3)(input_shape)\n",
    "tower_3 = Conv1D(filters=filters, kernel_size=7, activation='relu', input_shape=(760, 1))(tower_3)\n",
    "tower_3 = MaxPooling1D(pool_size=pool)(tower_3)\n",
    "tower_3 = Dropout(0.5)(tower_3)'''\n",
    "\n",
    "tower_4 = MaxPooling1D(pool_size=4)(input_shape)\n",
    "tower_4 = Conv1D(filters=filters, kernel_size=7, activation='relu', input_shape=(760, 1))(tower_4)\n",
    "tower_4 = MaxPooling1D(pool_size=pool)(tower_4)\n",
    "tower_4 = Dropout(0.5)(tower_4)\n",
    "\n",
    "merged = concatenate([tower_1,tower_4],axis=1)\n",
    "#merged = Flatten()(merged)\n",
    "\n",
    "lstm = Bidirectional(LSTM(cells,activation='sigmoid',return_sequences=True))(merged)\n",
    "lstm = Bidirectional(LSTM(cells,activation='sigmoid'))(merged)\n",
    "\n",
    "out = Dense(50,activation='relu')(merged)\n",
    "out = Dropout(0.5)(out)\n",
    "out = Dense(10,activation='relu')(out)\n",
    "out = Flatten()(out)\n",
    "out = Dense(1,activation='relu')(out)\n",
    "\n",
    "model = keras.Model(input_shape,out)\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "model.compile(loss = \"mse\", metrics=['mse'], optimizer = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_62\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           [(None, 760, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_231 (MaxPooling1D (None, 380, 1)       0           input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_233 (MaxPooling1D (None, 253, 1)       0           input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_235 (MaxPooling1D (None, 190, 1)       0           input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1057 (Conv1D)            (None, 754, 20)      160         input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1058 (Conv1D)            (None, 374, 20)      160         max_pooling1d_231[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1059 (Conv1D)            (None, 247, 20)      160         max_pooling1d_233[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1060 (Conv1D)            (None, 184, 20)      160         max_pooling1d_235[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_230 (MaxPooling1D (None, 377, 20)      0           conv1d_1057[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_232 (MaxPooling1D (None, 187, 20)      0           conv1d_1058[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_234 (MaxPooling1D (None, 123, 20)      0           conv1d_1059[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_236 (MaxPooling1D (None, 92, 20)       0           conv1d_1060[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 377, 20)      0           max_pooling1d_230[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 187, 20)      0           max_pooling1d_232[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 123, 20)      0           max_pooling1d_234[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 92, 20)       0           max_pooling1d_236[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 779, 20)      0           dropout_40[0][0]                 \n",
      "                                                                 dropout_41[0][0]                 \n",
      "                                                                 dropout_42[0][0]                 \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_159 (Dense)               (None, 779, 50)      1050        concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 779, 50)      0           dense_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 779, 10)      510         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 7790)         0           dense_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_161 (Dense)               (None, 1)            7791        flatten_33[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 9,991\n",
      "Trainable params: 9,991\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16111 samples, validate on 2844 samples\n",
      "Epoch 1/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0082 - mse: 1.0082 - val_loss: 0.9967 - val_mse: 0.9967\n",
      "Epoch 2/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0026 - mse: 1.0026 - val_loss: 0.9963 - val_mse: 0.9963\n",
      "Epoch 3/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0009 - mse: 1.0009 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 4/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0007 - mse: 1.0007 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 5/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0006 - mse: 1.0006 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 6/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0007 - mse: 1.0007 - val_loss: 0.9963 - val_mse: 0.9963\n",
      "Epoch 7/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0008 - mse: 1.0008 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 8/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0007 - mse: 1.0007 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 9/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0003 - mse: 1.0003 - val_loss: 0.9963 - val_mse: 0.9963\n",
      "Epoch 10/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0004 - mse: 1.0004 - val_loss: 0.9963 - val_mse: 0.9963\n",
      "Epoch 11/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0007 - mse: 1.0007 - val_loss: 0.9963 - val_mse: 0.9963\n",
      "Epoch 12/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0004 - mse: 1.0004 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 13/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0002 - mse: 1.0002 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 14/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0008 - mse: 1.0008 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 15/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0006 - mse: 1.0006 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 16/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0005 - mse: 1.0005 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 17/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0005 - mse: 1.0005 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 18/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0006 - mse: 1.0006 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 19/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0001 - mse: 1.0001 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 20/500\n",
      "16111/16111 [==============================] - 29s 2ms/sample - loss: 1.0005 - mse: 1.0005 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 21/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0001 - mse: 1.0001 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 22/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0004 - mse: 1.0004 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 23/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 0.9999 - mse: 0.9999 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 24/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0002 - mse: 1.0002 - val_loss: 0.9963 - val_mse: 0.9963\n",
      "Epoch 25/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0001 - mse: 1.0001 - val_loss: 0.9964 - val_mse: 0.9964se: 1\n",
      "Epoch 26/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0002 - mse: 1.0002 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 27/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9999 - mse: 0.9999 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 28/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0009 - mse: 1.0009 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 29/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0003 - mse: 1.0003 - val_loss: 0.9964 - val_mse: 0.99649 - mse: 1 - ETA: 1s - loss: 1.0024 - mse: - ETA: 0s - loss: 1.0016 \n",
      "Epoch 30/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0003 - mse: 1.0003 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 31/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0001 - mse: 1.0001 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 32/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9963 - val_mse: 0.9963\n",
      "Epoch 33/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 1.0004 - mse: 1.0004 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 34/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 0.9986 - mse: 0.9986 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 35/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 1.0000 - mse: 1.0000 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 36/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 37/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 0.9998 - mse: 0.9998 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 38/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9999 - mse: 0.9999 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 39/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 40/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 0.9997 - mse: 0.9997 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 41/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9993 - mse: 0.9993 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 42/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9987 - mse: 0.9987 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 43/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9990 - mse: 0.9990 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 44/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9991 - mse: 0.9991 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 45/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9988 - mse: 0.9988 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 46/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 47/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9994 - mse: 0.9994 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 48/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9987 - mse: 0.9987 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 49/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9991 - mse: 0.9991 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 50/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9989 - mse: 0.9989 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 51/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9983 - mse: 0.9983 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 52/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9988 - mse: 0.9988 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 53/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9989 - mse: 0.9989 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 54/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9982 - mse: 0.9982 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 55/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9983 - mse: 0.9983 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 56/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9984 - mse: 0.9984 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 57/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9988 - mse: 0.9988 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 58/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9987 - mse: 0.9987 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 59/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9989 - mse: 0.9989 - val_loss: 0.9965 - val_mse: 0.9965 loss: 0.9966 - ms - ETA: 8s \n",
      "Epoch 60/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9981 - mse: 0.9981 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 61/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9983 - mse: 0.9983 - val_loss: 0.9964 - val_mse: 0.9964.9897 - mse: 0\n",
      "Epoch 62/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9979 - mse: 0.9979 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 63/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9977 - mse: 0.9977 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 64/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9973 - mse: 0.9973 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 65/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9976 - mse: 0.9976 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 66/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9971 - mse: 0.9971 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 67/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9974 - mse: 0.9974 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 68/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9969 - mse: 0.9969 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 69/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9975 - mse: 0.9975 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 70/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9983 - mse: 0.9983 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 71/500\n",
      "16111/16111 [==============================] - 29s 2ms/sample - loss: 0.9973 - mse: 0.9973 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 72/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9972 - mse: 0.9972 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 73/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9978 - mse: 0.9978 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 74/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9977 - mse: 0.9977 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 75/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9976 - mse: 0.9976 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 76/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9969 - mse: 0.9969 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 77/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9963 - mse: 0.9963 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 78/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9962 - mse: 0.9962 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 79/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 0.9970 - mse: 0.9970 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 80/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9964 - mse: 0.9964 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 81/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9970 - mse: 0.9970 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 82/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9975 - mse: 0.9975 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 83/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9974 - mse: 0.9974 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 84/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9967 - mse: 0.9967 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 85/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9969 - mse: 0.9969 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 86/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9971 - mse: 0.9971 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 87/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9965 - mse: 0.9965 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 88/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9963 - mse: 0.9963 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 89/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9961 - mse: 0.9961 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 90/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9959 - mse: 0.9959 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 91/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9966 - mse: 0.9966 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 92/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9961 - mse: 0.9962 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 93/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9954 - mse: 0.9954 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 94/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9969 - mse: 0.9969 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 95/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9956 - mse: 0.9956 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 96/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9963 - mse: 0.9963 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 97/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9957 - mse: 0.9957 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 98/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9958 - mse: 0.9958 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 99/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9965 - mse: 0.9965 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 100/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9957 - mse: 0.9957 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 101/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9955 - mse: 0.9955 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 102/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9949 - mse: 0.9949 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 103/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9954 - mse: 0.9954 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 104/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9952 - mse: 0.9952 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 105/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9958 - mse: 0.9958 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 106/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9958 - mse: 0.9958 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 107/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9947 - mse: 0.9947 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 108/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9942 - mse: 0.9942 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 109/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9945 - mse: 0.9945 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 110/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9957 - mse: 0.9957 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 111/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9954 - mse: 0.9954 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 112/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9947 - mse: 0.9947 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 113/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9939 - mse: 0.9939 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 114/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9959 - mse: 0.9959 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 115/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9950 - mse: 0.9950 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 116/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9946 - mse: 0.9946 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 117/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9942 - mse: 0.9942 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 118/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9950 - mse: 0.9950 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 119/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9941 - mse: 0.9941 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 120/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9940 - mse: 0.9940 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 121/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9946 - mse: 0.9946 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 122/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9950 - mse: 0.9950 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 123/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 0.9945 - mse: 0.9945 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 124/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 0.9937 - mse: 0.9937 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 125/500\n",
      "16111/16111 [==============================] - 31s 2ms/sample - loss: 0.9929 - mse: 0.9929 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 126/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9940 - mse: 0.9940 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 127/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9936 - mse: 0.9936 - val_loss: 0.9965 - val_mse: 0.9965\n",
      "Epoch 128/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9940 - mse: 0.9940 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 129/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9938 - mse: 0.9938 - val_loss: 0.9967 - val_mse: 0.9967\n",
      "Epoch 130/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9948 - mse: 0.9948 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 131/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9938 - mse: 0.9938 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 132/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9925 - mse: 0.9925 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 133/500\n",
      "16111/16111 [==============================] - 30s 2ms/sample - loss: 0.9924 - mse: 0.9924 - val_loss: 0.9966 - val_mse: 0.9966\n",
      "Epoch 134/500\n",
      " 3672/16111 [=====>........................] - ETA: 22s - loss: 1.0158 - mse: 1.0158"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-474a619a5a0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m   \u001b[0mconstant_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    790\u001b[0m   \"\"\"\n\u001b[0;32m    791\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrepresentable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m     \"\"\"\n\u001b[1;32m--> 933\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "history = model.fit(x, y, epochs=500, verbose=1,batch_size=3, validation_split=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(history.history['categorical_accuracy'])\n",
    "#plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuarcy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "#plt.ylim(bottom=0.1,top=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 48  30  64 143 143  60]\n",
      " [ 44  31  72 137 141  56]\n",
      " [ 75  33 116 190 217  62]\n",
      " [105  46 127 258 281  82]\n",
      " [ 93  38 113 221 240  80]\n",
      " [ 70  37 100 153 196  53]]\n"
     ]
    }
   ],
   "source": [
    "def unencode(matrix):\n",
    "    new_matrix = np.zeros(matrix.shape[0])\n",
    "    for i in range(matrix.shape[0]):\n",
    "        val = np.argmax(matrix[i])\n",
    "        new_matrix[i] = classes[val]\n",
    "    return new_matrix\n",
    "\n",
    "y_pred = model.predict(x[15000:], verbose=0)\n",
    "\n",
    "classes = [0,1,2,3,4,5]\n",
    "cm = confusion_matrix(unencode(y)[15000:],unencode(y_pred),labels=classes)\n",
    "plt.imshow(cm,cmap='jet')\n",
    "plt.xlabel('Predicted y-values')\n",
    "plt.ylabel('Actual y-values')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "good = []\n",
    "\n",
    "print(cm)\n",
    "print(len(np.where(unencode(y_pred)==unencode(y)[15000:])[0])/len(y[15000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('deepbot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of metrics is set from ['accuracy'] (default) to ['accuracy']\n",
      "Generated models will be trained on subset of the data (subset size: 10000).\n",
      "Training model 0 CNN\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 7.0923 - accuracy: 0.2243 - val_loss: 1.9095 - val_accuracy: 0.2277loss:\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 10s 993us/sample - loss: 1.9361 - accuracy: 0.2296 - val_loss: 2.0658 - val_accuracy: 0.1980\n",
      "Epoch 00002: early stopping\n",
      "Training model 1 DeepConvLSTM\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 1.9238 - accuracy: 0.2233 - val_loss: 2.1339 - val_accuracy: 0.1900\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 77s 8ms/sample - loss: 1.8517 - accuracy: 0.2342 - val_loss: 1.7963 - val_accuracy: 0.1900\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 1.7523 - accuracy: 0.2324 - val_loss: 1.7893 - val_accuracy: 0.2277\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 1.7715 - accuracy: 0.2252 - val_loss: 1.7996 - val_accuracy: 0.2277\n",
      "Epoch 00004: early stopping\n",
      "Training model 2 ResNet\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 25s 3ms/sample - loss: 1.7638 - accuracy: 0.2205 - val_loss: 1.7789 - val_accuracy: 0.2277\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 22s 2ms/sample - loss: 1.7437 - accuracy: 0.2313 - val_loss: 1.7861 - val_accuracy: 0.2040\n",
      "Epoch 00002: early stopping\n",
      "Training model 3 InceptionTime\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 34s 3ms/sample - loss: 1.7906 - accuracy: 0.2152 - val_loss: 1.7704 - val_accuracy: 0.2290\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 31s 3ms/sample - loss: 1.7448 - accuracy: 0.2287 - val_loss: 1.7831 - val_accuracy: 0.2003\n",
      "Epoch 00002: early stopping\n",
      "Training model 4 CNN\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 5s 500us/sample - loss: 3.9910 - accuracy: 0.2242 - val_loss: 2.1925 - val_accuracy: 0.1977\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 4s 414us/sample - loss: 2.1328 - accuracy: 0.2310 - val_loss: 1.9792 - val_accuracy: 0.2270\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 4s 415us/sample - loss: 2.0679 - accuracy: 0.2298 - val_loss: 2.0110 - val_accuracy: 0.2063\n",
      "Epoch 00003: early stopping\n",
      "Training model 5 InceptionTime\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 17s 2ms/sample - loss: 1.8135 - accuracy: 0.2255 - val_loss: 1.8149 - val_accuracy: 0.2277\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 1.7448 - accuracy: 0.2329 - val_loss: 1.7940 - val_accuracy: 0.2277 8s - loss: 1.7365 - accuracy - ETA: 8s - los - ETA: 7s - - ETA: 4s - loss: 1.7389 - accuracy - ETA: 3s - los - ETA: 2s - loss: 1.7420 - accuracy - ETA: 2s - loss: 1.7424 - accu - ETA: 2s - loss: 1.7424 - accuracy - ETA: 2s - loss: 1.7420  - ETA: 1s - loss: 1.7428 - accu - ETA: 1s - loss: 1.7432 - accuracy: 0.23 - ETA: 1s - loss: 1.7433 - accuracy:  - ETA: 0s - loss: 1.7437 - accuracy: 0.23 - ETA: 0s - los\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 1.7439 - accuracy: 0.2294 - val_loss: 1.7802 - val_accuracy: 0.1900 9s - loss: 1.7394 - accura - ETA: 9s - loss: 1.7399 -  - ETA: 9s - ETA: 7s - loss: 1.7436 - accu - ETA: 7s - loss: 1.7433 - ac - ETA: 7s - loss: 1.7432 - accuracy:  - ETA:  - ETA: 5s - loss: 1.7 - ETA: 5s - loss: 1.7448 - accuracy: 0.22 - ETA: 5s - loss: 1.7453 - ac - ETA: 4s - l - ETA: 3s - los - ETA: 2s - - ETA: 1s - loss: - ETA: 0s - loss:\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 1.7445 - accuracy: 0.2294 - val_loss: 1.8036 - val_accuracy: 0.1900 1.7507 - acc - ETA: 10s - loss: 1.7456 - accur - ETA: 9s - loss: 1. - - ETA: 4s - loss: 1 - ETA - ETA: 2s - loss: 1.7460 - accura - ETA: 2s - loss: 1.7464 -  - ETA: 2s - loss: 1.7457 - ac - ETA: 1s - loss: 1 - ETA: 0s - los\n",
      "Epoch 00004: early stopping\n",
      "Training model 6 ResNet\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 67s 7ms/sample - loss: 1.7707 - accuracy: 0.2257 - val_loss: 1.7726 - val_accuracy: 0.1983\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 62s 6ms/sample - loss: 1.7452 - accuracy: 0.2227 - val_loss: 1.7819 - val_accuracy: 0.2120\n",
      "Epoch 00002: early stopping\n",
      "Training model 7 DeepConvLSTM\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 69s 7ms/sample - loss: 2.1022 - accuracy: 0.2212 - val_loss: 1.9204 - val_accuracy: 0.1900\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 65s 7ms/sample - loss: 1.8041 - accuracy: 0.2334 - val_loss: 1.8041 - val_accuracy: 0.2277\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 65s 7ms/sample - loss: 1.7568 - accuracy: 0.2298 - val_loss: 1.7944 - val_accuracy: 0.2277\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 65s 7ms/sample - loss: 1.7479 - accuracy: 0.2275 - val_loss: 1.7892 - val_accuracy: 0.1900\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 65s 7ms/sample - loss: 1.7456 - accuracy: 0.2319 - val_loss: 1.7835 - val_accuracy: 0.1900\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 65s 7ms/sample - loss: 1.7429 - accuracy: 0.2352 - val_loss: 1.7890 - val_accuracy: 0.2180\n",
      "Epoch 00006: early stopping\n",
      "Training model 8 DeepConvLSTM\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 72s 7ms/sample - loss: 1.8270 - accuracy: 0.2316 - val_loss: 1.8102 - val_accuracy: 0.1900\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 68s 7ms/sample - loss: 1.7596 - accuracy: 0.2313 - val_loss: 1.7894 - val_accuracy: 0.1900\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 68s 7ms/sample - loss: 1.7454 - accuracy: 0.2267 - val_loss: 1.7935 - val_accuracy: 0.1900\n",
      "Epoch 00003: early stopping\n",
      "Training model 9 ResNet\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 1.7574 - accuracy: 0.2243 - val_loss: 1.8015 - val_accuracy: 0.1973  - ETA: 3s - loss: 1.7614 - accu - ETA: 2s - ETA: 1s - loss: 1.7606 - ac - ETA: 0s - loss: 1.7598 -  - ETA: 0s - loss: 1.7587 - accura\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 9s 897us/sample - loss: 1.7413 - accuracy: 0.2328 - val_loss: 1.7906 - val_accuracy: 0.1933\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 9s 903us/sample - loss: 1.7398 - accuracy: 0.2310 - val_loss: 1.7999 - val_accuracy: 0.1907.7406 - accura - ETA: 2s - loss: 1.7405 - accuracy:  - ETA: 0s - l\n",
      "Epoch 00003: early stopping\n",
      "Training model 10 CNN\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 24s 2ms/sample - loss: 3.1255 - accuracy: 0.2169 - val_loss: 2.2870 - val_accuracy: 0.2193\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 21s 2ms/sample - loss: 2.0662 - accuracy: 0.2348 - val_loss: 1.9999 - val_accuracy: 0.1983\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 21s 2ms/sample - loss: 1.8908 - accuracy: 0.2342 - val_loss: 1.9029 - val_accuracy: 0.2180\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 21s 2ms/sample - loss: 1.8337 - accuracy: 0.2266 - val_loss: 1.8262 - val_accuracy: 0.1900\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 21s 2ms/sample - loss: 1.7953 - accuracy: 0.2309 - val_loss: 1.8514 - val_accuracy: 0.1927\n",
      "Epoch 00005: early stopping\n",
      "Training model 11 InceptionTime\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 22s 2ms/sample - loss: 1.7658 - accuracy: 0.2240 - val_loss: 1.7825 - val_accuracy: 0.1900\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 20s 2ms/sample - loss: 1.7415 - accuracy: 0.2308 - val_loss: 1.7812 - val_accuracy: 0.2200\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 20s 2ms/sample - loss: 1.7404 - accuracy: 0.2269 - val_loss: 1.7867 - val_accuracy: 0.2277\n",
      "Epoch 00003: early stopping\n",
      "Training model 12 CNN\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "   20/10000 [..............................] - ETA: 12:22:27WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[62320,1349] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Tile_9 (defined at C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_distributed_function_1315041]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-9c1c49f07299>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmcfly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_architecture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfind_best_architecture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_best_architecture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m51000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m18000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m18000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber_of_models\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnr_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubset_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'file.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\mcfly\\find_architecture.py\u001b[0m in \u001b[0;36mfind_best_architecture\u001b[1;34m(X_train, y_train, X_val, y_val, verbose, number_of_models, nr_epochs, subset_size, outputpath, model_path, metric, class_weight, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m                                                                     \u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                                                                     \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                                                                     class_weight=class_weight)\n\u001b[0m\u001b[0;32m    287\u001b[0m     \u001b[0mbest_model_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_accuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_model_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\mcfly\\find_architecture.py\u001b[0m in \u001b[0;36mtrain_models_on_samples\u001b[1;34m(X_train, y_train, X_val, y_val, models, nr_epochs, subset_size, verbose, outputfile, model_path, early_stopping_patience, batch_size, metric, class_weight)\u001b[0m\n\u001b[0;32m    129\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[62320,1349] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Tile_9 (defined at C:\\Users\\811261\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_distributed_function_1315041]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "from mcfly.find_architecture import find_best_architecture\n",
    "\n",
    "best_model, best_params, best_model_type, knn_acc = find_best_architecture(x[:15000],y[:51000],x[15000:18000],y[15000:18000],verbose=1,number_of_models=50,nr_epochs=10,subset_size=10000,outputpath='file.txt',metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13500 samples, validate on 1500 samples\n",
      "Epoch 1/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7649 - accuracy: 0.2296 - val_loss: 1.7865 - val_accuracy: 0.1960 accuracy: 0. - ETA: 3s - loss: 1 - ETA: 2s - loss: 1.7655 - accuracy:  - ETA: 2s - loss: 1.7655 -  - ETA: 2s - loss: 1.7650 - accuracy - ETA: 1s - - ETA: 0s - l\n",
      "Epoch 2/50\n",
      "13500/13500 [==============================] - 58s 4ms/sample - loss: 1.7537 - accuracy: 0.2245 - val_loss: 1.7795 - val_accuracy: 0.2060: 1.7560 - accura - ETA: 32s -  - ETA: 27s - loss: 1.7527 - accu - ETA: 27s - loss: 1.7525 - ac - ETA: 26s - loss: 1.7538 - - ETA: 25s - loss: 1.7543 - acc - ETA: 24s - loss: 1.75 - ETA: 23s - loss: 1.7545 -  - ETA: 14s - loss: - ETA - ETA: 0s - loss: 1\n",
      "Epoch 3/50\n",
      "13500/13500 [==============================] - 58s 4ms/sample - loss: 1.7493 - accuracy: 0.2296 - val_loss: 1.7756 - val_accuracy: 0.2273\n",
      "Epoch 4/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7478 - accuracy: 0.2270 - val_loss: 1.7805 - val_accuracy: 0.2280\n",
      "Epoch 5/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7475 - accuracy: 0.2251 - val_loss: 1.7776 - val_accuracy: 0.22539s - loss: 1.7516 -  - ETA: 48s -  - ETA: 41s - loss: 1. - ETA: 37s - loss: 1.7 - ETA: 35s  - ETA: 33s - loss: 1.7486 - acc - E - E - ETA - ETA: 0s - loss: 1.7472 - ac\n",
      "Epoch 6/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7467 - accuracy: 0.2274 - val_loss: 1.7991 - val_accuracy: 0.2327 33s - loss: 1.7491 - a - ETA: 32s -  - ETA: 30s - loss: 1.7485 - accuracy: 0.2 - ETA: 30s - loss: 1.7483  - ETA: 29 - ETA: 27s - loss: 1.7496  - ETA: 26s - loss: 1.7492 - accurac - ETA: 25s - loss: 1.7486 - - ETA: 24s - loss: 1.74 - ETA: 20s - loss: 1.7479 - accuracy: - ETA: 20s - loss: 1.7482  - ETA: 18s - loss: 1.7484 - ETA: 17s - loss: 1.7489 - accuracy: 0.225 - ETA: 17s - loss - ETA: 16s - loss: 1.7483 - accuracy: 0. - ETA: 15s - loss: 1.7483 - accuracy: 0. - ETA: 15s - loss: 1.7485 - accura - ETA: 15 - ETA: 12s - loss: 1.7480 - ETA: 11s - loss: 1.7481 - accuracy:  - ETA: 11s - loss: 1 - ETA: 9s - loss: 1.74 - ETA: 9s - loss: 1.7471 -  - ETA: 8s - loss: 1.7476 -  - ETA: 6s - loss: 1.7480 - accuracy: 0. - ETA: 6s - loss: - E - ETA: 2s - -\n",
      "Epoch 7/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7469 - accuracy: 0.2260 - val_loss: 1.7849 - val_accuracy: 0.1993oss: 1.7418 - accuracy: 0.244 - ETA: 52s - loss: 1.7415 - accurac - ETA: 51s - loss: 1.7441 - ac - ETA: 48s - loss: 1.7491 - accuracy: 0.239 - ETA: 48s - loss: 1.7497 - accuracy: - ETA: 47s - loss: 1. - ETA: 43s - loss: 1.7463 - accur - ETA: 42s - loss: 1.7456  - ETA: 41s - loss: 1.7 - ETA: 40s - loss: 1.7478 - accuracy: 0 - ETA: 31s - l - ETA: 27s - los - ETA: 22s - loss: 1.7463 - accuracy:  - ETA: 22s - loss: 1.74 - ETA: 21s - loss:  - ETA: 19s - loss: 1.7457 - accur - ETA: 19s - loss: 1.7465 - a - ETA: 18s - loss: 1.74 - ETA: 16s - loss: 1. - ETA: 15s - loss: 1.7477 - accurac - ETA: 14s - loss: 1.7476 -  - ETA: 13s - loss: 1.7474  - ETA: 12s -  - ETA: 10s - loss: 1.7476 - -  - ETA: 0s - loss: 1.7475 - accuracy: 0. - ETA: 0s - loss: 1.7473 \n",
      "Epoch 8/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7465 - accuracy: 0.2284 - val_loss: 1.7760 - val_accuracy: 0.2247 - loss: 1.7661 - ETA: 51s -  - ETA: 44s - loss: 1.7 - ETA: 42s - loss: 1.7501 - acc - ETA: 39s - loss: 1 - ETA: 38s - loss: 1.7536 -  - ETA: 28s - loss: 1.7520 - accu - ETA: 28s - - ETA:  -  - ETA: 16s - los - ETA: 14s - loss: 1.7465 - accuracy: - ETA: 13s - loss: 1.746 - ETA: 12s - loss: 1.7463 - accuracy: 0.226 - ETA: 12s - loss: 1.7463 \n",
      "Epoch 9/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7462 - accuracy: 0.2313 - val_loss: 1.7789 - val_accuracy: 0.1953 56s - l - ET - ETA: 43s - loss: 1.7 - ETA: 41s - loss: 1.7418 -  - - ETA: 16s - loss: 1.7451 - accuracy: 0 - ETA: 15s - ETA:\n",
      "Epoch 10/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7462 - accuracy: 0.2317 - val_loss: 1.7781 - val_accuracy: 0.228051s - loss: 1.7451 - accuracy: 0. - ETA: 51s - - ET - ET - ETA: 35s - loss: 1.7453 - - ETA: 34s - - ETA: 32s - loss: 1.7468 - accurac - ETA: 31s - loss: 1.7470 - accurac - ETA: 31s - loss: 1.7468 -  - ETA: 30s - loss: 1.7456 - accura - ETA: 29s - loss: 1.7452 - accuracy: 0 - ETA: 29s - loss: 1.7452 - accuracy: 0 - ETA: 28s - loss:  - ETA: 27s - loss: 1. - ETA: 23s - loss: 1.7473 -  - ETA: 22s -  - - ETA: 17s - loss: 1.7482 - acc - ETA: 16s - loss: 1.7474 - accuracy:  - ETA: 16s - loss: 1.7468 - accuracy: 0.23 - ETA: 16 - ETA: - ETA: 0s - loss: 1.7461 - accuracy\n",
      "Epoch 11/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7461 - accuracy: 0.2281 - val_loss: 1.7729 - val_accuracy: 0.2260 - loss: 1.7408 - a - ETA: 52s - loss: 1.7421 - ETA: 50s - loss: 1.7424 - ac - ETA: 50s - los - ETA: 48s - loss: 1.748 - ETA: 46s - loss: 1.7466 - accuracy: 0.23 - ETA - ETA:  - ETA: 42s - loss: 1.7453 - accu - ETA: 41s - loss: 1.7454 -  - ETA: 40s - loss: 1.7457 - accura - ETA: 39s - loss: 1.7466 - acc - ETA: 39s - loss: 1.7467 - accuracy: 0.23 - ETA: 39s - loss: 1 - ETA: 37s - loss: 1.7438 -  - ETA: 36s - loss: 1.7438 - accuracy:  - ETA: 36s - loss: 1. - ETA: 26s - loss: 1.7472 - acc - ETA: 25s - loss: 1.7472 - accuracy - ET - ETA: 17s - loss: 1.7466 - ac - ETA: 16s - loss: 1.7470 - ETA: 15s - loss: 1.7459 - a - ETA: 14s - loss: 1.7457 - accura - ETA: 14s - loss: 1.7458 - accuracy: - ETA:  - ETA: 5s - loss: 1.7 - ETA: 4s - l - ETA: 0s -\n",
      "Epoch 12/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7462 - accuracy: 0.2287 - val_loss: 1.7762 - val_accuracy: 0.2280s - E - ETA: 45s - loss: 1.7544 - accuracy - ETA: 45s - loss: 1.7545  - ETA: 44s - lo - ETA: 42s - loss: 1.7517 - accuracy:  - ET - ETA: 39s - loss: 1.7505 - accu - ETA: 38s - loss: 1.7489 - accuracy - ETA: 38s - loss: - ETA - ETA: 0s - loss: 1.7460 - \n",
      "Epoch 13/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7461 - accuracy: 0.2259 - val_loss: 1.7774 - val_accuracy: 0.1920 - loss: 1.7400 - accuracy: 0 - ETA: 40s - loss: 1.7400 - accuracy: 0. - ETA: 40s - los - ETA: 38s - loss: 1.7432 - accur - ETA: 38s - loss: 1.7439 - ETA: 34s - loss: 1.7458 - ac - ETA: 33s  - ETA: 31s - loss: - ETA: 30s - loss: 1.7473 - accura - ETA: 29s - loss: 1.74 - ETA: 25s - loss: 1 - ETA: 24s - loss: 1.7479 - accu - ETA: 23s - loss: 1.7481 - accuracy:  - ETA: 22s - loss: 1.7476 - accu - ETA: 22s - loss: 1.74 - ETA: 20s - loss: 1.7474 - a - ETA: 20s - loss: 1.7477 - acc - ETA: 19s -  - ETA: 17s - loss: 1.7474 - accur - ETA: 16 - ETA: 14s - loss: 1.7475 - accur - - ETA: 3s - loss: 1.746 - ETA:  - ETA: 2s - loss:\n",
      "Epoch 14/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7461 - accuracy: 0.2269 - val_loss: 1.7761 - val_accuracy: 0.2267ETA: 50s - loss: 1.7427 - accu - ETA: 49s - loss: 1.7440 - accura - ETA: 48s - loss: - ETA:  - ETA: 42s - loss: 1.7414 - accurac - ETA: 41s - loss: 1.7410 - acc - ETA: 40s - loss: 1.7409  - ETA: 39s - loss: 1.7440 - accuracy:  - ETA: 39s - loss: 1.7443 - - ETA: 38s - loss: 1.7439 - accuracy: - ETA: 37s - ETA: 35s - los - ETA: 34s - loss: 1.7414 - accuracy: 0 - ETA: 33s - loss: 1.7431 - accu - ETA: 33s - loss: 1.7430 - ETA: 32s - loss: 1.7428 - accuracy: 0 - ETA: 31s - loss: 1 - ETA: 27s - loss: 1. - ETA: 26s - l - ETA: 21s - loss: 1.7461  - ETA: 17s - loss: 1.7453 - accu - ETA: 17s - loss: 1.7444 - accura - ETA: 16s - loss: 1.7445 - accuracy: 0. - ETA: 16s - loss: 1 - ETA: 14s - loss: 1.7450 - accuracy: - ETA: 14s - loss: 1.7449 - ETA: 13s - loss: 1.7452 - accuracy: - ETA: 12s - loss: 1.7448 - accura - ETA: 12s - loss: 1.7450 - accuracy: 0.22 - ETA: 11s - loss: 1.7449 - accuracy: 0.228 - ETA: 11s - loss: 1.7450 - accur - ETA: 11s - loss: 1.7451 - accu - ETA: 10s - loss: - E - ETA: 2s - loss: 1.7453 - ac - ETA: 2s - loss: 1.7453  - ETA: 1s - loss: 1.7453  - ETA: 1s - los - ETA: 0s - loss: 1.745\n",
      "Epoch 15/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7459 - accuracy: 0.2291 - val_loss: 1.7783 - val_accuracy: 0.2167ETA: 38s - loss: 1.7489 - a - ETA: 34s - loss - ETA: 32s -  - ETA: 31s - loss: 1.7471 - accuracy: 0.223 - ETA: 30s - loss: 1.7468 - accurac - ETA: 30s - - ETA: 28s - loss: 1.7455 - accurac - ETA: 27s - l - ETA: 26s - loss: 1.7460  - ETA: 25s - loss: 1.7454 - accuracy: 0 - ETA: 24s - loss:  - ETA: 23s - loss: 1.7456 -  - ETA: 19s - loss: 1.7461 - ETA: 15s - los - ETA: 13s - loss: 1.7 - ETA: 12s - loss: 1.7465 - accura - ETA: 11s -  - ETA: 10s - ETA: 8s - loss: 1.7465  - ETA: 4s - loss: - ETA: 3s -\n",
      "Epoch 16/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7458 - accuracy: 0.2302 - val_loss: 1.7810 - val_accuracy: 0.2180 - loss: 1.7711 - accuracy: 0.209 - ETA: 5 - ETA: 53s  - ETA: 41s - loss: 1.7459 - accuracy:  - ETA: 40s - loss: 1.7430 - accur - ETA: 39s - loss: 1.7456 - accuracy - ETA: 39s - loss: 1.7455 - accura - ETA: 38s - los - ETA: 37s - loss: 1.7444 - accuracy: 0 - ETA: 36s  - ETA: 29s - loss: 1.7438 - accuracy: - ETA: 28s - loss: 1.7432 - accuracy: 0. - ETA: 28s - loss: 1.7432 - a - ETA: 27s - loss: 1.7412 - - ETA: 26s - loss: - ETA: 25 - ETA: 17s - loss: 1.7450 - accura - ETA: 16s - loss: 1.7462 - accuracy: 0.23 - ETA: 16s - los - ETA: 14s - loss: 1.7452 - ac - ETA: 13s - loss: 1.7450 - accuracy - ETA: 1 - ETA: 11s - loss: 1.7443 - accu - ETA: 8s - loss: 1.744 - ETA: 8s - loss: 1.7453 - accuracy: 0.23 - ETA: 6s - loss: 1 - ETA: 6s - loss: 1.7462 - ac - ETA: 4s - loss: 1.7460 - ac\n",
      "Epoch 17/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7459 - accuracy: 0.2293 - val_loss: 1.7749 - val_accuracy: 0.2147.7389 - accuracy:  - ETA: 40s - los - ETA: 38s - loss: 1.7405 - accu - ETA: 38s - loss: 1.7416 - accuracy: 0 - ETA: 37s - loss: 1.7421 - accuracy: - ETA: 37s - loss - ETA: 35s - loss: 1.7417 - accuracy: 0.227 - ETA: 35s - loss: 1.7413 - accuracy: - ETA: 35s - loss: 1.7419 - accura - ETA: 34s -  - ETA: 30s - loss: 1.7417 - a - ETA: 23s - loss: 1  - ET - ETA: 14s - loss: 1.745 - ETA: 8s - loss: - ETA: 6s - loss: 1.746 - ETA: 4s - los - ETA: 3s - ETA: 1s - loss: 1.7 - ETA: 0s - los\n",
      "Epoch 18/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7458 - accuracy: 0.2277 - val_loss: 1.7800 - val_accuracy: 0.2020 loss: 1.7383 - accuracy: 0.232 - ETA: 56s - loss: 1.7468 - a - ETA: 54 - - ETA: 47s - - ETA: 42s - loss: 1.7487  - ETA: 41s - loss: 1.7470 -  - ETA: 4 - ETA: 38s - loss: 1.7449 - accu - ETA: 37s - loss: 1.7435 - acc - ETA: 36s - loss: 1.7432 - accu - ETA: 35s - loss: 1.7438 - accuracy: - ETA: 35s - loss: 1.7447 - accuracy: 0.2 - ETA: 35s - loss: 1.7444 - acc - ETA: 34s - loss: 1.7453 - accura - ETA: 33s - loss: 1.7450 - accuracy:  - ETA: 33s - loss:  - ETA: 32s - loss: 1.7462 - accur - ETA: 31s - loss:  - ETA: 29s - lo -\n",
      "Epoch 19/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7455 - accuracy: 0.2293 - val_loss: 1.7801 - val_accuracy: 0.2140oss: 1.7419 - accuracy: - ETA: 50s - loss:  - ETA: 48s - loss: - ETA: 46s - loss: 1 - ETA: 45s - loss: 1 - ETA: 44s - loss: 1.7399 - accuracy: - ETA: 43s - loss: 1.7396  - ETA: 42s - loss: 1.740 - ETA: 22s - loss: 1.7461 - accuracy: - ETA: 21s - l\n",
      "Epoch 20/50\n",
      "13500/13500 [==============================] - 59s 4ms/sample - loss: 1.7455 - accuracy: 0.2304 - val_loss: 1.7796 - val_accuracy: 0.1980 57s - loss: 1.7330 - accuracy:  - ETA: 56s - loss: 1.7367 -  - ETA: 55s - loss: 1.7393 - ac - ETA: 54s - loss: 1.7408 - accuracy: - ETA: 53s - loss: 1.7402 - accuracy: - ETA: 53s - loss: 1.7384 - accuracy:  - ETA: 5 - ETA: 47s - loss: 1.7377 - accura - ETA: 47s - loss: 1.7398 - accuracy - ET - ETA: 44s - loss: 1.7413 - accuracy: 0 - ETA: 43s - l - ETA: 42s - loss: 1.7451 - accuracy - ETA: 41s - loss: 1.7443 - accuracy: - ETA: 41s - loss: 1.7437 - accuracy: 0 - ETA: 40 - ETA: 38s - loss: 1.7423 - a - ETA: 37s - loss: 1.7428  - ETA: 3 - ETA: 31s - loss: 1.7411 - accur - ETA: 25s - loss: 1.7 - ETA: 24s - loss: - ETA: 22s - loss: 1.7440 - accuracy: - ETA: 22s - - ETA: 17s - loss: 1.7435 - accura - ET - ETA: 14s - loss: 1.7451 - accuracy: 0 - ETA: 14s - loss: 1.7452 - accurac - ETA: 13s - loss: 1.7452 - accurac - ETA: 3s - los - ETA: 2s - - ETA: 0s - loss: 1.7454 - accuracy\n",
      "Epoch 21/50\n",
      " 6417/13500 [=============>................] - ETA: 29s - loss: 1.7459 - accuracy: 0.2297- ETA: 55s -  -   - ETA: 30s - loss: 1.7468 - ac"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-a0774806f2ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model.fit(x[:15000], y[:15000], epochs=50, verbose=1,batch_size=3, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
